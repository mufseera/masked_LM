{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4663fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer,BertForMaskedLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7a150fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"After Abraham Lincoln won the November 1860 presidential \"\n",
    "        \"election on an anti-slavery platform, an initial seven \"\n",
    "        \"slave states declared their secession from the country \"\n",
    "        \"to form the Confederacy. War broke out in April 1861 \"\n",
    "        \"when secessionist forces attacked Fort Sumter in South \"\n",
    "        \"Carolina, just over a month after Lincoln's \"\n",
    "        \"inauguration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c343cfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c3ee2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text,return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2fa4a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df224ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[\"labels\"] = inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ce6e5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7077748",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "mask_arr = rand<.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04601182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False,  True, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True, False,  True,  True, False, False, False, False,\n",
       "         False, False, False, False,  True,  True,  True,  True, False, False,\n",
       "         False, False]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e6a4b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mask_array = rand<.15 * (inputs.input_ids!=101) * (inputs.input_ids!=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b0df5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False,  True, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True, False,  True,  True, False, False, False, False,\n",
       "         False, False, False, False,  True,  True,  True,  True, False, False,\n",
       "         False, False]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a56dfb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = torch.flatten(mask[0].nonzero()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "687204c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 42, 44, 45, 54, 55, 56, 57]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7330276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2, 42, 44, 45, 54, 55, 56, 57])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(mask[0].nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "323029de",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.input_ids [0,selection] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eeb828da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2044,   103,  5367,  2180,  1996,  2281,  7313,  4883,  2602,\n",
       "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
       "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
       "          1996, 18179,  1012,  2162,  3631,  2041,  1999,  2258,  6863,  2043,\n",
       "         22965,  2923,   103,  4457,   103,   103,  3334,  1999,  2148,  3792,\n",
       "          1010,  2074,  2058,  1037,   103,   103,   103,   103,  1055, 17331,\n",
       "          1012,   102]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f0df385",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a72e388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7246, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9df923e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'logits'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81a52d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 62, 30522])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3323602c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 42, 44, 45, 54, 55, 56, 57]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten((inputs.input_ids[0]==103).nonzero()).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c4c718",
   "metadata": {},
   "source": [
    "### masked language training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a88884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer,BertForMaskedLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4dadcc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceae446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./clean.txt\",\"r\") as fp:\n",
    "    text = fp.read().split(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fef53a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From my grandfather Verus I learned good morals and the government of my temper.',\n",
       " 'From the reputation and remembrance of my father, modesty and a manly character.',\n",
       " 'From my mother, piety and beneficence, and abstinence, not only from evil deeds, but even from evil thoughts; and further, simplicity in my way of living, far removed from the habits of the rich.',\n",
       " 'From my great-grandfather, not to have frequented public schools, and to have had good teachers at home, and to know that on such things a man should spend liberally.',\n",
       " \"From my governor, to be neither of the green nor of the blue party at the games in the Circus, nor a partizan either of the Parmularius or the Scutarius at the gladiators' fights; from him too I learned endurance of labour, and to want little, and to work with my own hands, and not to meddle with other people's affairs, and not to be ready to listen to slander.\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5de8967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text,return_tensors=\"pt\",max_length=512,truncation=True,padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd42eadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[\"labels\"] = inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "292bab4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([507, 512])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09fbec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = torch.rand(inputs.input_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90e32756",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_arr = rand<.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c55254a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_arr = mask_arr *(inputs.input_ids!=101) *(inputs.input_ids!=103) * (inputs.input_ids!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18f16bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([507, 512])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1031d443",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = []\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(torch.flatten(mask_arr[i].nonzero()).tolist())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a573b297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 11]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c6ab066",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    inputs.input_ids[i,selection[i]]=103\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b7d4275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2013,  2026,  ...,     0,     0,     0],\n",
       "        [  101,   103,  1996,  ...,     0,     0,     0],\n",
       "        [  101,  2013,  2026,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  3459,   103,  ...,     0,     0,     0],\n",
       "        [  101,  2043, 15223,  ...,     0,     0,     0],\n",
       "        [  101,  7887,  3288,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "299203df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "098f884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MediattaionDataset(Dataset):\n",
    "    def __init__(self,encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self,idx):\n",
    "        return {key: torch.tensor(value[idx]) for key,value in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48f3f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MediattaionDataset(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2532fd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2ecf0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset,batch_size=16,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b82149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device  = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f59d71dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b68cfc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "803d4897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mufseeramusthafa/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "# activate train mode\n",
    "model.train()\n",
    "# initialize optimizer\n",
    "optim = AdamW(model.parameters(),lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "84498afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.6875"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df54945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b19831d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/32 [00:00<?, ?it/s]/var/folders/d0/d01yx__169n424klbs_zty800000gn/T/ipykernel_4172/2060688347.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(value[idx]) for key,value in self.encodings.items()}\n",
      "Epoch 0: 100%|██████████████████████| 32/32 [16:44<00:00, 31.40s/it, loss=0.394]\n",
      "Epoch 1: 100%|███████████████████| 32/32 [1:06:58<00:00, 125.59s/it, loss=0.142]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # for our progress bar\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch in loop:\n",
    "        # initialize calculated gradients (from prev step)\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        # process\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        labels=labels)\n",
    "        # extract loss\n",
    "        loss = outputs.loss\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa00185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bdce0a4",
   "metadata": {},
   "source": [
    "### training with Trainer API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "028e8f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer,BertForMaskedLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "243e31fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From my grandfather Verus I learned good morals and the government of my temper.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33f09471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60cc1983",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text,truncation=True,max_length=512,padding=\"max_length\",return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffecbe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[\"labels\"] = inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9ecd6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_arr = torch.rand(inputs[\"input_ids\"].shape)\n",
    "mask_arr = (inputs.input_ids !=101) * (inputs.input_ids !=102) *(inputs.input_ids !=0) * (rand_arr<.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0d40606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False,  True,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False,  True, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dd40ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = []\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(torch.flatten(mask_arr[i].nonzero()).tolist())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d42c464",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    inputs.input_ids[i,selection[i]]=103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de61d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeditationsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e46cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class Meditation(Dataset):\n",
    "    def __init__(self,encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self,idx):\n",
    "        return{key :torch.tensor(value[idx]) for key,value in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2353b910",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = Meditation(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba12e862",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(output_dir = \"out\",\n",
    "                        per_device_train_batch_size=16,\n",
    "                        num_train_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9763ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ddfb6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=Dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76d71268",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd6ddc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
